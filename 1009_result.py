import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import platform
import re

# í•œê¸€ í°íŠ¸ ì„¤ì •
if platform.system() == 'Windows':
    plt.rcParams['font.family'] = 'Malgun Gothic'
elif platform.system() == 'Darwin':  # macOS
    plt.rcParams['font.family'] = 'AppleGothic'
else:  # Linux
    plt.rcParams['font.family'] = 'NanumGothic'

plt.rcParams['axes.unicode_minus'] = False

# CSV ì½ê¸°
df = pd.read_csv('ëŒ€ë‹µ ê²°ê³¼.csv')

# ì •ë‹µ ì •ë³´ - ì‹¤ì œ ì—”íŠ¸ë¦¬ ìƒ‰ìƒ
CORRECT_INFO = {
    'category': 'ì‹œì‘',
    'color_code': '#00B400',  # ì´ˆë¡ìƒ‰
    'color_names': ['ì´ˆë¡', 'ë…¹ìƒ‰', 'green', '#00B400'],
    'position': ['ìœ„', 'ìƒë‹¨', 'ë§¨ ìœ„', 'top', 'ì²«', 'ì²˜ìŒ']
}

def check_visual_color(answer_str):
    """HTML ì¹´ë“œì˜ ë°°ê²½ìƒ‰ í™•ì¸"""
    if 'background: linear-gradient' in answer_str:
        # ì¹´ë“œ ìƒ‰ìƒ ì½”ë“œ ì¶”ì¶œ
        color_pattern = r'#[0-9A-Fa-f]{6}'
        colors = re.findall(color_pattern, answer_str)
        
        # #00B400 ë˜ëŠ” ìœ ì‚¬í•œ ì´ˆë¡ìƒ‰ í™•ì¸
        for color in colors:
            if color.upper() in ['#00B400', '#00B400CC', '#00B400AA']:
                return True
            # RGB ê°’ìœ¼ë¡œ ì´ˆë¡ìƒ‰ ê³„ì—´ í™•ì¸ (G ê°’ì´ ë†’ê³  R,Bê°€ ë‚®ìŒ)
            if len(color) == 7:
                try:
                    r = int(color[1:3], 16)
                    g = int(color[3:5], 16) 
                    b = int(color[5:7], 16)
                    if g > 150 and r < 100 and b < 100:  # ì´ˆë¡ìƒ‰ ê³„ì—´
                        return True
                except:
                    pass
    return False

def evaluate_answer_new(answer, question):
    """
    ìƒˆë¡œìš´ í‰ê°€ ê¸°ì¤€í‘œì— ë”°ë¥¸ ë‹µë³€ í‰ê°€ (ì‹œê°ì  ìƒ‰ìƒ í‘œí˜„ í¬í•¨)
    """
    if pd.isna(answer):
        return {
            'ì •í™•ì„±': 0, 'ì¦‰ë‹µì„±': 0, 'ì‚¬ìš©ì„±': 0, 'êµìœ¡ì _ê°€ì¹˜': 0,
            'ì´ì ': 0, 'ìƒ‰ìƒ_í‘œí˜„_ë°©ì‹': 'ì—†ìŒ'
        }
    
    answer_str = str(answer)
    answer_lower = answer_str.lower()
    lines = answer_str.split('\n')
    char_count = len(answer_str.strip())
    
    # ìƒ‰ìƒ í‘œí˜„ ë°©ì‹ ì´ˆê¸°í™”
    color_expression = 'ì—†ìŒ'
    
    # 1. ì •í™•ì„± (30ì )
    accuracy_score = 0
    
    # ì¹´í…Œê³ ë¦¬ ì •í™•ë„ (5ì )
    if 'ì‹œì‘' in answer_str and ('ì¹´í…Œê³ ë¦¬' in answer_str or 'ìœ„ì¹˜:' in answer_str):
        accuracy_score += 5
    
    # ë¸”ë¡ ìƒ‰ìƒ (3ì ) - í…ìŠ¤íŠ¸ ë˜ëŠ” ì‹œê°ì  í‘œí˜„
    color_correct = False
    
    # í…ìŠ¤íŠ¸ë¡œ ìƒ‰ìƒ ì–¸ê¸‰
    for color in CORRECT_INFO['color_names']:
        if color in answer_lower:
            color_correct = True
            color_expression = 'í…ìŠ¤íŠ¸'
            break
    
    # HTML ì¹´ë“œ ë°°ê²½ìƒ‰ìœ¼ë¡œ í‘œí˜„
    if check_visual_color(answer_str):
        color_correct = True
        color_expression = 'ì‹œê°ì '
    
    if color_correct:
        accuracy_score += 3
    elif 'ìƒ‰' in answer_str or 'color' in answer_lower:
        # ìƒ‰ìƒ ì–¸ê¸‰í–ˆì§€ë§Œ í‹€ë¦¼
        accuracy_score += 0
        color_expression = 'í‹€ë¦¼'
    else:
        # ìƒ‰ìƒ ì–¸ê¸‰ ì•ˆí•¨
        accuracy_score += 1
    
    # ì˜ëª»ëœ ìƒ‰ìƒ ê°ì 
    wrong_colors = ['ë…¸ë€', 'yellow', 'ì£¼í™©', 'orange', 'ë¹¨ê°„', 'red', 'íŒŒë€', 'blue']
    for wrong in wrong_colors:
        if wrong in answer_lower and not color_correct:
            accuracy_score -= 5
            color_expression = 'í‹€ë¦¼'
            break
    
    # ë¸”ë¡ ì´ë¦„ (5ì )
    if 'ì‹œì‘í•˜ê¸° ë²„íŠ¼ì„ í´ë¦­í–ˆì„ ë•Œ' in answer_str:
        accuracy_score += 5
    elif 'ì‹œì‘í•˜ê¸° ë²„íŠ¼' in answer_str or 'í´ë¦­í–ˆì„ ë•Œ' in answer_str:
        accuracy_score += 3
    elif 'ì‹œì‘' in answer_str:
        accuracy_score += 2
    
    # ìœ„ì¹˜ ì„¤ëª… (3ì )
    position_mentioned = False
    for pos in CORRECT_INFO['position']:
        if pos in answer_str:
            accuracy_score += 3
            position_mentioned = True
            break
    if not position_mentioned:
        accuracy_score += 1  # ì–¸ê¸‰ ì•ˆí•¨
    
    # ê¸°ëŠ¥ ì„¤ëª… (5ì )
    function_keywords = ['í”„ë¡œê·¸ë¨', 'ì‹œì‘', 'ì´ë²¤íŠ¸', 'ì‹¤í–‰', 'ë²„íŠ¼', 'í´ë¦­']
    function_count = sum(1 for keyword in function_keywords if keyword in answer_str)
    if function_count >= 2:
        accuracy_score += 5
    elif function_count >= 1:
        accuracy_score += 3
    
    accuracy_score = max(0, min(30, accuracy_score))
    
    # 2. ì¦‰ë‹µì„± (25ì )
    immediacy_score = 0
    
    # í•µì‹¬ ì •ë³´ ìš°ì„  ì œì‹œ (10ì )
    core_info_line = -1
    for i, line in enumerate(lines[:7]):
        if any(key in line for key in ['ìœ„ì¹˜', 'ì¹´í…Œê³ ë¦¬', 'ì‹œì‘', 'ğŸ“']):
            core_info_line = i
            break
    
    # HTML ì¹´ë“œëŠ” ë°”ë¡œ ì‹œê°ì  ì •ë³´ ì œê³µ
    if '<div style="' in answer_str[:200]:  # ì´ˆë°˜ì— ì¹´ë“œê°€ ìˆìœ¼ë©´
        immediacy_score += 8
    elif 0 <= core_info_line <= 2:
        immediacy_score += 10
    elif 3 <= core_info_line <= 5:
        immediacy_score += 6
    elif core_info_line > 5:
        immediacy_score += 2
    
    # ì •ë³´ ì ‘ê·¼ì„± (10ì )
    if 'ğŸ“' in answer_str or 'ìœ„ì¹˜:' in answer_str:
        immediacy_score += 10
    elif 'ì¹´í…Œê³ ë¦¬' in answer_str:
        immediacy_score += 5
    
    # ë¶ˆí•„ìš”í•œ ë‚´ìš© ê°ì  (-5ì )
    unnecessary_phrases = ['ì¢‹ì€ ì§ˆë¬¸', 'ì•ˆë…•', 'ë°˜ê°€ì›Œ', 'í›Œë¥­í•œ', 'ì¢‹ì•„ìš”']
    unnecessary_count = sum(1 for phrase in unnecessary_phrases if phrase in answer_str)
    immediacy_score -= min(5, unnecessary_count * 2)
    
    immediacy_score = max(0, min(25, immediacy_score))
    
    # 3. ì‚¬ìš©ì„± (25ì )
    usability_score = 0
    
    # ê¸€ ê¸¸ì´ ì ì ˆì„± (10ì )
    if 100 <= char_count <= 200:
        usability_score += 10
    elif 201 <= char_count <= 400:
        usability_score += 8
    elif 401 <= char_count <= 600:
        usability_score += 5
    elif 601 <= char_count <= 800:
        usability_score += 3
    elif char_count > 800:
        usability_score += 1
    
    # êµ¬ì¡°í™” (5ì )
    structure_markers = ['â€¢', '1.', 'â–¶', '###', '**', '<div', 'style=']
    structure_count = sum(1 for marker in structure_markers if marker in answer_str)
    if structure_count >= 3:
        usability_score += 5
    elif structure_count >= 1:
        usability_score += 3
    
    # ì‹œê°ì  ë„ì›€ (5ì )
    # HTML ì¹´ë“œ í˜•ì‹ì´ë©´ ìµœê³ ì 
    if 'background: linear-gradient' in answer_str:
        usability_score += 5
    elif any(emoji in answer_str for emoji in ['ğŸ“', 'â–¶ï¸', 'ğŸŸ¢', 'ğŸ’¡', 'ğŸ“Œ']):
        usability_score += 4
    elif '**' in answer_str or '##' in answer_str:
        usability_score += 2
    
    # ì—°ë ¹ ì í•©ì„± (5ì )
    complex_terms = ['ì¸ìŠ¤í„´ìŠ¤', 'íŒŒë¼ë¯¸í„°', 'ë©”ì†Œë“œ', 'ê°ì²´', 'API', 'function', 'variable']
    if not any(term in answer_str for term in complex_terms):
        usability_score += 5
    else:
        usability_score += 2
    
    usability_score = min(25, usability_score)
    
    # 4. êµìœ¡ì  ê°€ì¹˜ (20ì )
    educational_score = 0
    
    # ì˜ˆì‹œ ì œê³µ (7ì )
    if ('ì˜ˆ' in answer_str or 'ì˜ˆì‹œ' in answer_str) and ('ì½”ë“œ' in answer_str or 'ë¸”ë¡' in answer_str):
        educational_score += 7
    elif 'ì‚¬ìš©' in answer_str and 'ë°©ë²•' in answer_str:
        educational_score += 4
    
    # ê´€ë ¨ ì •ë³´ (7ì )
    if any(phrase in answer_str for phrase in ['ë¹„ìŠ·í•œ', 'ê´€ë ¨', 'ì°¨ì´', 'êµ¬ë¶„', 'í—·ê°ˆ']):
        educational_score += 7
    elif 'ì„¤ëª…' in answer_str:
        educational_score += 4
    
    # ì¶”ê°€ í•™ìŠµ ìœ ë„ (6ì )
    if any(phrase in answer_str for phrase in ['ë” ì•Œê³  ì‹¶', 'ì¶”ê°€', 'ë‹¤ìŒ', 'ì‚¬ìš©ë²• ì•Œë ¤ì¤˜', 'ì˜ˆì œ ë³´ì—¬ì¤˜']):
        educational_score += 6
    elif '?' in answer_str:
        educational_score += 3
    
    educational_score = min(20, educational_score)
    
    # ì´ì  ê³„ì‚°
    total_score = accuracy_score + immediacy_score + usability_score + educational_score
    
    return {
        'ì •í™•ì„±': accuracy_score,
        'ì¦‰ë‹µì„±': immediacy_score,
        'ì‚¬ìš©ì„±': usability_score,
        'êµìœ¡ì _ê°€ì¹˜': educational_score,
        'ì´ì ': total_score,
        'ìƒ‰ìƒ_í‘œí˜„_ë°©ì‹': color_expression
    }

# ê° LLMë³„ ì ìˆ˜ ê³„ì‚°
results = []
detailed_analysis = []

for idx, row in df.iterrows():
    for llm in ['GPT', 'ì œë¯¸ë‚˜ì´', 'ê°œë°œ ì±—ë´‡']:
        if llm in df.columns:
            scores = evaluate_answer_new(row[llm], row['ì§ˆë¬¸'])
            results.append({
                'ì§ˆë¬¸ë²ˆí˜¸': row['ë²ˆí˜¸'],
                'ì§ˆë¬¸': row['ì§ˆë¬¸'],
                'LLM': llm,
                'ì´ì ': scores['ì´ì '],
                'ì •í™•ì„±': scores['ì •í™•ì„±'],
                'ì¦‰ë‹µì„±': scores['ì¦‰ë‹µì„±'],
                'ì‚¬ìš©ì„±': scores['ì‚¬ìš©ì„±'],
                'êµìœ¡ì _ê°€ì¹˜': scores['êµìœ¡ì _ê°€ì¹˜']
            })
            
            # ìƒì„¸ ë¶„ì„ ë°ì´í„°
            detailed_analysis.append({
                'ì§ˆë¬¸ë²ˆí˜¸': row['ë²ˆí˜¸'],
                'LLM': llm,
                'ìƒ‰ìƒ_í‘œí˜„': scores['ìƒ‰ìƒ_í‘œí˜„_ë°©ì‹']
            })

# ê²°ê³¼ DataFrame ìƒì„±
results_df = pd.DataFrame(results)
analysis_df = pd.DataFrame(detailed_analysis)

# ì‹œê°í™”
fig, axes = plt.subplots(2, 3, figsize=(18, 12))

# ìƒ‰ìƒ ì„¤ì •
colors = {'GPT': '#FF6B6B', 'ì œë¯¸ë‚˜ì´': '#4ECDC4', 'ê°œë°œ ì±—ë´‡': '#45B7D1'}

# 1. ì „ì²´ í‰ê·  ì ìˆ˜ ë¹„êµ
ax1 = axes[0, 0]
avg_scores = results_df.groupby('LLM')['ì´ì '].mean().round(1)
bars = ax1.bar(avg_scores.index, avg_scores.values, 
                color=[colors[llm] for llm in avg_scores.index])
ax1.set_title('ì „ì²´ í‰ê·  ì ìˆ˜ ë¹„êµ', fontsize=14, fontweight='bold')
ax1.set_ylabel('í‰ê·  ì ìˆ˜ (100ì  ë§Œì )', fontsize=12)
ax1.set_ylim(0, 100)

for bar, score in zip(bars, avg_scores.values):
    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
             f'{score:.1f}ì ', ha='center', fontweight='bold', fontsize=12)

# 2. í‰ê°€ ì˜ì—­ë³„ ì ìˆ˜
ax2 = axes[0, 1]
eval_categories = ['ì •í™•ì„±', 'ì¦‰ë‹µì„±', 'ì‚¬ìš©ì„±', 'êµìœ¡ì _ê°€ì¹˜']
category_avg = results_df.groupby('LLM')[eval_categories].mean()

x = np.arange(len(eval_categories))
width = 0.25

for i, llm in enumerate(['GPT', 'ì œë¯¸ë‚˜ì´', 'ê°œë°œ ì±—ë´‡']):
    if llm in category_avg.index:
        values = category_avg.loc[llm].values
        ax2.bar(x + i*width, values, width, label=llm, color=colors[llm], alpha=0.8)

ax2.set_xlabel('í‰ê°€ ì˜ì—­', fontsize=12)
ax2.set_ylabel('í‰ê·  ì ìˆ˜', fontsize=12)
ax2.set_title('í‰ê°€ ì˜ì—­ë³„ ì ìˆ˜ ë¹„êµ', fontsize=14, fontweight='bold')
ax2.set_xticks(x + width)
ax2.set_xticklabels(['ì •í™•ì„±\n(30ì )', 'ì¦‰ë‹µì„±\n(25ì )', 'ì‚¬ìš©ì„±\n(25ì )', 'êµìœ¡ì  ê°€ì¹˜\n(20ì )'])
ax2.legend()
ax2.grid(axis='y', alpha=0.3)

# 3. ë ˆì´ë” ì°¨íŠ¸
ax3 = axes[0, 2]
angles = np.linspace(0, 2*np.pi, len(eval_categories), endpoint=False).tolist()
angles += angles[:1]

ax3 = plt.subplot(2, 3, 3, projection='polar')
for llm in ['GPT', 'ì œë¯¸ë‚˜ì´', 'ê°œë°œ ì±—ë´‡']:
    if llm in category_avg.index:
        values = category_avg.loc[llm].tolist()
        values += values[:1]
        ax3.plot(angles, values, 'o-', linewidth=2, label=llm, color=colors[llm])
        ax3.fill(angles, values, alpha=0.25, color=colors[llm])

ax3.set_xticks(angles[:-1])
ax3.set_xticklabels(eval_categories, fontsize=10)
ax3.set_ylim(0, 30)
ax3.set_title('ì˜ì—­ë³„ ì„±ëŠ¥ ë ˆì´ë” ì°¨íŠ¸', fontsize=14, fontweight='bold', pad=20)
ax3.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))

# 4. ì§ˆë¬¸ë³„ ì ìˆ˜ íˆíŠ¸ë§µ
ax4 = axes[1, 0]
pivot_data = results_df.pivot_table(values='ì´ì ', index='ì§ˆë¬¸ë²ˆí˜¸', columns='LLM')
pivot_data = pivot_data.head(10)
im = ax4.imshow(pivot_data.T, cmap='RdYlGn', aspect='auto', vmin=0, vmax=100)
ax4.set_xticks(range(len(pivot_data)))
ax4.set_xticklabels([f'Q{int(i)}' for i in pivot_data.index])
ax4.set_yticks(range(len(pivot_data.columns)))
ax4.set_yticklabels(pivot_data.columns)
ax4.set_title('ì§ˆë¬¸ë³„ ì ìˆ˜ íˆíŠ¸ë§µ (ìƒìœ„ 10ê°œ)', fontsize=14, fontweight='bold')
cbar = plt.colorbar(im, ax=ax4)
cbar.set_label('ì ìˆ˜', rotation=270, labelpad=15)

# 5. ì ìˆ˜ ë¶„í¬ ë°•ìŠ¤í”Œë¡¯
ax5 = axes[1, 1]
data_for_box = []
labels_for_box = []
for llm in ['GPT', 'ì œë¯¸ë‚˜ì´', 'ê°œë°œ ì±—ë´‡']:
    if llm in results_df['LLM'].values:
        data_for_box.append(results_df[results_df['LLM']==llm]['ì´ì '].values)
        labels_for_box.append(llm)

if data_for_box:
    bp = ax5.boxplot(data_for_box, labels=labels_for_box, patch_artist=True)
    for patch, llm in zip(bp['boxes'], labels_for_box):
        patch.set_facecolor(colors[llm])
        patch.set_alpha(0.7)

ax5.set_ylabel('ì ìˆ˜', fontsize=12)
ax5.set_title('ì ìˆ˜ ë¶„í¬ ë¹„êµ', fontsize=14, fontweight='bold')
ax5.grid(axis='y', alpha=0.3)
ax5.set_ylim(0, 100)

# 6. ê°œì„ ìœ¨ í‘œì‹œ
ax6 = axes[1, 2]
if 'ê°œë°œ ì±—ë´‡' in avg_scores.index and 'GPT' in avg_scores.index and 'ì œë¯¸ë‚˜ì´' in avg_scores.index:
    improvement = pd.DataFrame({
        'vs GPT': [(avg_scores['ê°œë°œ ì±—ë´‡'] / avg_scores['GPT'] - 1) * 100],
        'vs ì œë¯¸ë‚˜ì´': [(avg_scores['ê°œë°œ ì±—ë´‡'] / avg_scores['ì œë¯¸ë‚˜ì´'] - 1) * 100]
    })
    bars = ax6.bar(improvement.columns, improvement.values[0], color=['#95E77E', '#95E77E'])
    ax6.set_title('ê°œë°œ ì±—ë´‡ ì„±ëŠ¥ ê°œì„ ìœ¨', fontsize=14, fontweight='bold')
    ax6.set_ylabel('ê°œì„ ìœ¨ (%)', fontsize=12)
    ax6.axhline(y=0, color='black', linestyle='-', linewidth=0.5)
    ax6.grid(axis='y', alpha=0.3)
    
    for bar, val in zip(bars, improvement.values[0]):
        ax6.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                 f'{val:.1f}%', ha='center', fontweight='bold')

plt.tight_layout()
plt.savefig('llm_evaluation_results_visual.png', dpi=300, bbox_inches='tight')
plt.show()

# ìµœì¢… ì ìˆ˜í‘œ ì¶œë ¥
print("\n" + "="*60)
print("ì‹œì‘ ì¹´í…Œê³ ë¦¬ ë¸”ë¡ ìœ„ì¹˜ ì§ˆë¬¸ í‰ê°€ ê²°ê³¼")
print("="*60)
for llm in avg_scores.index:
    print(f"{llm}: {avg_scores[llm]:.1f}ì ")
print("-"*60)

if 'ê°œë°œ ì±—ë´‡' in avg_scores.index:
    if 'GPT' in avg_scores.index:
        print(f"ê°œë°œ ì±—ë´‡ì´ GPT ëŒ€ë¹„ {(avg_scores['ê°œë°œ ì±—ë´‡']/avg_scores['GPT']-1)*100:.1f}% {'ë†’ì€' if avg_scores['ê°œë°œ ì±—ë´‡'] > avg_scores['GPT'] else 'ë‚®ì€'} ì ìˆ˜")
    if 'ì œë¯¸ë‚˜ì´' in avg_scores.index:
        print(f"ê°œë°œ ì±—ë´‡ì´ Gemini ëŒ€ë¹„ {(avg_scores['ê°œë°œ ì±—ë´‡']/avg_scores['ì œë¯¸ë‚˜ì´']-1)*100:.1f}% {'ë†’ì€' if avg_scores['ê°œë°œ ì±—ë´‡'] > avg_scores['ì œë¯¸ë‚˜ì´'] else 'ë‚®ì€'} ì ìˆ˜")

# ìƒ‰ìƒ í‘œí˜„ ë°©ì‹ ë¶„ì„
print("\nìƒ‰ìƒ í‘œí˜„ ë°©ì‹ ë¶„ì„:")
color_analysis = analysis_df.groupby(['LLM', 'ìƒ‰ìƒ_í‘œí˜„']).size().unstack(fill_value=0)
print(color_analysis)

# ì˜ì—­ë³„ ìƒì„¸ ì ìˆ˜
print("\nì˜ì—­ë³„ í‰ê·  ì ìˆ˜:")
print(category_avg.round(1))
